# --- 机器人QQ平台设置 (NcatBot) ---
# 机器人运行的QQ号，请替换为你的机器人QQ号
BT_UIN=YOUR_BOT_QQ_NUMBER
# 机器人管理员QQ号，请替换为你的管理员QQ号
ROOT=YOUR_ADMIN_QQ_NUMBER
# 测试消息发送目标QQ号（可选，用于调试），请替换为目标QQ号或留空
# TARGET_QQ=

# --- 机器人昵称 (来自README.md, 具体用法取决于是否有代码解析它) ---
# 如果你的代码需要解析这个列表字符串，请确保有相应逻辑
# NICKNAME=["小助手", "助手"]

# --- LLM 提供商选择 ---
# 指定使用哪个大模型提供商: "zhipu", "openai", "claude"
LLM_PROVIDER=zhipu

# --- ZhipuAI (智谱GLM) API 配置 (如果 LLM_PROVIDER="zhipu") ---
# 智谱AI API Key，请替换为你的API Key
ZHIPUAI_API_KEY=YOUR_ZHIPUAI_API_KEY
# 智谱AI模型名称，例如 glm-4, glm-4v, glm-3-turbo 等，请根据你的需求填写
GLM_MODEL=glm-4-flash-250414
# 智谱AI最大token数，请根据你的需求填写
GLM_MAX_TOKENS=8192
# GLM_ENABLE_WEB_SEARCH: 对于智谱AI，此选项通常由代码 (llm_api.py) 强制或默认为 true。
# 在 .env 中设置可能不会覆盖代码中的强制逻辑。请根据需要调整
GLM_ENABLE_WEB_SEARCH=true
# 智谱模型的温度参数，请根据你的需求填写
GLM_TEMPERATURE=0.7

# --- OpenAI API 配置 (如果 LLM_PROVIDER="openai") ---
# OpenAI API Key，请替换为你的API Key
OPENAI_API_KEY=your_openai_api_key_here
# OpenAI模型名称，例如 gpt-4, gpt-4-turbo-preview 等，请根据你的需求填写
OPENAI_MODEL=gpt-3.5-turbo
# OpenAI最大token数，请根据你的需求填写
OPENAI_MAX_TOKENS=4096
# OPENAI_TEMPERATURE=0.7 # (可选) 如果希望控制温度，需修改 qq_bot.py 或 llm_api.py 以读取并使用此变量

# --- Anthropic (Claude) API 配置 (如果 LLM_PROVIDER="claude") ---
# Anthropic API Key，请替换为你的API Key
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Claude模型名称，例如 claude-3-opus-20240229, claude-2.1 等，请根据你的需求填写
CLAUDE_MODEL=claude-3-sonnet-20240229
# Claude最大token数，请根据你的需求填写
CLAUDE_MAX_TOKENS=4096
# CLAUDE_TEMPERATURE=0.7 # (可选) 如果希望控制温度，需修改 qq_bot.py 或 llm_api.py 以读取并使用此变量

# --- 通用 LLM 后备设置 (如果特定提供商的设置未提供或未被代码直接读取) ---
# LLM_MAX_TOKENS=2048 # 通用后备最大token数，如果特定模型的未设置
# LLM_TEMPERATURE=0.7 # 通用后备温度，如果特定模型的未设置且代码中未硬编码或传递

# --- QQ Bot 插件 (qq_bot.py) 特定设置 ---
# qq_bot.py 使用的系统提示词，请根据你的需求填写
QQBOT_SYSTEM_PROMPT="你是一个名为ChatGLM-Flash的AI助手，具备联网搜索能力，可以用它来回答需要实时信息的问题。"
# qq_bot.py 保留的对话历史长度 (不包括系统提示词本身)，请根据你的需求填写
# 如果希望总对话消息数(含system prompt)接近原来bot.py的41条, 这里应该设置为 40
QQBOT_MAX_HISTORY_LENGTH="40"